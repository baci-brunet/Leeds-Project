{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62224ee4-dbc4-428b-97a4-fbfe748245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "# Cache stopword set so access is faster\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\"'s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11256fb-87b5-4811-9f09-1d3593965142",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_regex = re.compile(r'\\b%s\\b' % r'\\b|\\b'.join(map(re.escape, stop_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6270cbdc-367d-45f1-bf67-a59a0b06de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_excel('../../Data/Other/wiki_bigrams.xlsx')\n",
    "wiki['Info1'] = wiki['Info1'].apply(lambda info: str(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a6a82b-51f8-414d-982a-b1678958c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki['Name'] = wiki['Info1'].apply(lambda text: str(str(text).split(';')[0].lower().strip()))\n",
    "# wiki['Info1'] = wiki['Info1'].apply(lambda text: ';'.join(str(text).split(';')[1:]))\n",
    "# wiki = wiki.drop_duplicates(subset=None, keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0de25b2-ae67-4bc3-a79f-7844e831c06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = '../../Data/MetaData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e271a5-6992-4ff6-961a-a62ca2a793ca",
   "metadata": {},
   "source": [
    "**Iterate through Directories and Match Corresponding Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dda88f5f-db54-48fd-ae84-15f24c643c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in os.listdir(meta_data):\n",
    "    if file != '.DS_Store' and file != '.ipynb_checkpoints' and file != 'README.txt':\n",
    "        files.append(os.path.join(meta_data, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "924df758-a4fc-4b25-81e4-64f617562af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(name):\n",
    "    return big_regex.sub('', name).strip()\n",
    "\n",
    "def remove_punc(text):\n",
    "    punctuation = '''(){};'\"\\,<>/@#%^&*_~'''\n",
    "    return ';'.join(word.translate(str.maketrans('', '', punctuation)).strip() for word in text.split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf9564d-c062-4174-a9d0-ed09a39bc356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Format Files: 82.36394596099854 seconds\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "start = time.time()\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = ['Title', 'Orgs', 'Persons', 'Other']\n",
    "    df['Persons'] = df['Persons'].apply(lambda per: re.sub('_', ' ', str(per)))\n",
    "    df['Persons'] = df['Persons'].apply(lambda per: ';'.join(remove_stopwords(name) for name in str(per).split(';')))\n",
    "    df['Persons'] = df['Persons'].apply(lambda per: remove_punc(per))\n",
    "    df['Persons Frequency'] = df['Persons'].apply(lambda names: \n",
    "                                              collections.Counter([name for name in names.split(';') if len(name.split()) > 1]))\n",
    "    df['Persons Frequency'] = df['Persons Frequency'].apply(lambda d: \n",
    "                                                            ', '.join(['{}: {}'.format(k, v) for k,v in d.items()]))\n",
    "    # Added 02/22/2022\n",
    "    df['Persons Frequency'] = df['Persons Frequency'].apply(\n",
    "        lambda list_of_names: ', '.join(['{}: {}'.format(re.sub(r'\\w*\\d\\w*', '', name.split(': ')[0].strip()), name.split(': ')[1]) for name in str(list_of_names).split(', ') if str(name).split(': ') != ['nan']]))  \n",
    "\n",
    "    del df['Persons']\n",
    "    del df['Orgs']\n",
    "    del df['Other']\n",
    "    dataframes.append((file, df))\n",
    "end = time.time()\n",
    "print('Time to Format Files: {} seconds'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1af4ba9-6212-453d-bef9-c6a56b62aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2012.20210920.csv: 364.1233208179474 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2013.20210920.csv: 15.108757972717285 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2014.20210920.csv: 190.24271726608276 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2015.20210920.csv: 335.5486238002777 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2012.20210920.csv: 343.12055015563965 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2015.20210920.csv: 385.0451169013977 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2019.20210920.csv: 358.2010838985443 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2015.20210920.csv: 172.6181240081787 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2012.20210920.csv: 40.202451944351196 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2013.20210920.csv: 157.83097195625305 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2014.20210920.csv: 142.03291416168213 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2018.20210920.csv: 364.3858790397644 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2013.20210920.csv: 115.93952488899231 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2014.20210920.csv: 105.72408080101013 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2014.20210920.csv: 372.6171941757202 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2015.20210920.csv: 237.70872592926025 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2013.20210920.csv: 378.81140995025635 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2014.20210920.csv: 350.13231015205383 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2013.20210920.csv: 367.8674318790436 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2015.20210920.csv: 138.4439778327942 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2012.20210920.csv: 129.49072098731995 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2018.20210920.csv: 138.20189905166626 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2019.20210920.csv: 483.0154552459717 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2018.20210920.csv: 220.2554910182953 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2019.20210920.csv: 472.0513529777527 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2015.20210920.csv: 271.8248710632324 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2012.20210920.csv: 256.8976957798004 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2019.20210920.csv: 239.17545080184937 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2019.20210920.csv: 124.08444595336914 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2013.20210920.csv: 291.07658290863037 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2014.20210920.csv: 254.2194800376892 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2018.20210920.csv: 219.4566798210144 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2019.20210920.csv: 207.7453851699829 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2018.20210920.csv: 499.6915159225464 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2018.20210920.csv: 473.06356501579285 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2020.20210920.csv: 481.3414149284363 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2016.20210920.csv: 335.26510405540466 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.MSNBC.2017.20210920.csv: 352.82891297340393 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2016.20210920.csv: 232.4540617465973 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2016.20210920.csv: 450.6906249523163 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2017.20210920.csv: 269.0740830898285 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2016.20210920.csv: 428.3592789173126 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2020.20210920.csv: 451.58101296424866 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2020.20210920.csv: 504.53577280044556 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2020.20210920.csv: 239.03117632865906 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2017.20210920.csv: 154.32238006591797 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNN.2017.20210920.csv: 600.3190591335297 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FOXNEWS.2017.20210920.csv: 426.7163121700287 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2016.20210920.csv: 273.3380699157715 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.FBC.2017.20210920.csv: 212.54152488708496 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2020.20210920.csv: 124.97535514831543 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.CNBC.2016.20210920.csv: 161.7094349861145 seconds\n",
      "Time Taken to Merge Wiki for ../Data/MetaData/Metadata.NERS.Bloomberg.2020.20210920.csv: 158.5089681148529 seconds\n"
     ]
    }
   ],
   "source": [
    "for entry in dataframes:\n",
    "    start = time.time()\n",
    "    entry[1]['Bigrams of Interest'] = None\n",
    "    for i in range(len(entry[1].index)):\n",
    "        boi = []\n",
    "        for name in entry[1].loc[i, 'Persons Frequency'].split(', '):\n",
    "            # person_ind = wiki.loc[wiki['Name'] == name.split(': ')[0].lower()].index[0]\n",
    "            if len(wiki.loc[wiki['Name'] == name.split(': ')[0].lower()]) > 0 and len(str(wiki.loc[wiki.loc[wiki['Name'] == name.split(': ')[0].lower()].index[0], 'Info1']).split(';')) > 1:  # If name is in wiki_bigrams \n",
    "                boi.append(name)\n",
    "        if len(boi) > 0:\n",
    "            entry[1].loc[i, 'Bigrams of Interest'] = ', '.join(boi)\n",
    "        else:\n",
    "            entry[1].loc[i, 'Bigrams of Interest'] = 'No Hits'\n",
    "    end = time.time()\n",
    "    print('Time Taken to Merge Wiki for {}: {} seconds'.format(entry[0], end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8567d629-1000-4201-b021-9f6283a76231",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataframes:\n",
    "    entry[1].to_csv('../../OutputPersons/PersonsBreakdown/{}.csv'.format('_'.join(entry[0].split('.')[4:6])), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54dd77d4-3e96-460f-a59a-c930936bdd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  118.95132207870483 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2012.20210920.csv\n",
      "Time:  4.959038972854614 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2013.20210920.csv\n",
      "Time:  58.912769079208374 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2014.20210920.csv\n",
      "Time:  112.88255906105042 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2015.20210920.csv\n",
      "Time:  102.45041799545288 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2012.20210920.csv\n",
      "Time:  119.15330505371094 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2015.20210920.csv\n",
      "Time:  119.52055811882019 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2019.20210920.csv\n",
      "Time:  56.22607207298279 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2015.20210920.csv\n",
      "Time:  12.428621768951416 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2012.20210920.csv\n",
      "Time:  39.997377157211304 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2013.20210920.csv\n",
      "Time:  36.231377840042114 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2014.20210920.csv\n",
      "Time:  120.94249701499939 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2018.20210920.csv\n",
      "Time:  33.26890993118286 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2013.20210920.csv\n",
      "Time:  31.653566122055054 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2014.20210920.csv\n",
      "Time:  119.50876069068909 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2014.20210920.csv\n",
      "Time:  76.73598217964172 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2015.20210920.csv\n",
      "Time:  117.73082494735718 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2013.20210920.csv\n",
      "Time:  105.69079494476318 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2014.20210920.csv\n",
      "Time:  111.84810900688171 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2013.20210920.csv\n",
      "Time:  37.018776178359985 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2015.20210920.csv\n",
      "Time:  34.23662781715393 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2012.20210920.csv\n",
      "Time:  34.943527936935425 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2018.20210920.csv\n",
      "Time:  164.2981882095337 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2019.20210920.csv\n",
      "Time:  59.68714690208435 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2018.20210920.csv\n",
      "Time:  159.7529900074005 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2019.20210920.csv\n",
      "Time:  84.73787784576416 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2015.20210920.csv\n",
      "Time:  85.11345314979553 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2012.20210920.csv\n",
      "Time:  75.50344896316528 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2019.20210920.csv\n",
      "Time:  31.63058590888977 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2019.20210920.csv\n",
      "Time:  97.6071150302887 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2013.20210920.csv\n",
      "Time:  80.55572032928467 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2014.20210920.csv\n",
      "Time:  70.6314160823822 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2018.20210920.csv\n",
      "Time:  55.82301092147827 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2019.20210920.csv\n",
      "Time:  175.43898606300354 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2018.20210920.csv\n",
      "Time:  162.64994192123413 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2018.20210920.csv\n",
      "Time:  155.9208550453186 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2020.20210920.csv\n",
      "Time:  117.93288111686707 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2016.20210920.csv\n",
      "Time:  120.37731218338013 seconds for  ../Data/MetaData/Metadata.NERS.MSNBC.2017.20210920.csv\n",
      "Time:  77.03937792778015 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2016.20210920.csv\n",
      "Time:  156.41091990470886 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2016.20210920.csv\n",
      "Time:  80.2780110836029 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2017.20210920.csv\n",
      "Time:  150.09049272537231 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2016.20210920.csv\n",
      "Time:  148.2980649471283 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2020.20210920.csv\n",
      "Time:  172.95471501350403 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2020.20210920.csv\n",
      "Time:  74.20973896980286 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2020.20210920.csv\n",
      "Time:  42.07388186454773 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2017.20210920.csv\n",
      "Time:  161.62210607528687 seconds for  ../Data/MetaData/Metadata.NERS.CNN.2017.20210920.csv\n",
      "Time:  154.51406288146973 seconds for  ../Data/MetaData/Metadata.NERS.FOXNEWS.2017.20210920.csv\n",
      "Time:  88.52422332763672 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2016.20210920.csv\n",
      "Time:  71.50259900093079 seconds for  ../Data/MetaData/Metadata.NERS.FBC.2017.20210920.csv\n",
      "Time:  30.95427703857422 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2020.20210920.csv\n",
      "Time:  46.680206060409546 seconds for  ../Data/MetaData/Metadata.NERS.CNBC.2016.20210920.csv\n",
      "Time:  40.93307709693909 seconds for  ../Data/MetaData/Metadata.NERS.Bloomberg.2020.20210920.csv\n"
     ]
    }
   ],
   "source": [
    "attributes = ['Male', 'Female', 'Politician', 'American', 'Foreign', 'Republican', 'Democratic', 'Chief Executive Officer', \n",
    "              'Chief Financial Officer', 'Hedge Fund Manager', 'Investor', 'Billionaire', 'Lawyer', 'Television Reporters', 'Television Hosts']\n",
    "\n",
    "for entry in dataframes:\n",
    "    start = time.time()\n",
    "    entry[1]['Count of Unique Indivuals'] = None\n",
    "    entry[1]['Count by Mention of Individuals'] = None\n",
    "    for i in range(len(entry[1].index)):\n",
    "        unique, total = {}, {}\n",
    "        for att in attributes:  # Initialize entry dictionary\n",
    "            unique[att] = 0\n",
    "            total[att] = 0\n",
    "        if entry[1].loc[i, 'Bigrams of Interest'] != 'No Hits':\n",
    "            for name in entry[1].loc[i, 'Bigrams of Interest'].split(', '):\n",
    "                person_index = wiki.loc[wiki['Name'] == name.split(': ')[0].lower()].index[0] # Grab index of person in wiki_bigrams\n",
    "                for att in attributes: # Find out who they are\n",
    "                    if att == 'Female':\n",
    "                        if att.lower() in wiki.loc[person_index, 'Info1'].lower() or 'women' in wiki.loc[person_index, 'Info1'].lower():\n",
    "                            unique[att] += 1\n",
    "                            total[att] += 1*int(name.split(': ')[1])\n",
    "                    elif att == 'Male':\n",
    "                        if 'female' not in wiki.loc[person_index, 'Info1'].lower() and 'women' not in wiki.loc[person_index, 'Info1'].lower():\n",
    "                            unique['Male'] += 1\n",
    "                            total['Male'] += 1*int(name.split(': ')[1])\n",
    "                    elif att == 'Foreign':\n",
    "                        if 'american' not in wiki.loc[person_index, 'Info1'].lower():\n",
    "                            unique['Foreign'] += 1\n",
    "                            total['Foreign'] += 1*int(name.split(': ')[1])\n",
    "                    else:\n",
    "                        if att.lower() in wiki.loc[person_index, 'Info1'].lower():\n",
    "                            unique[att] += 1\n",
    "                            total[att] += 1*int(name.split(': ')[1])\n",
    "            entry[1].loc[i, 'Count of Unique Indivuals'] = ', '.join(['{}: {}'.format(k, v) for k, v in unique.items()])\n",
    "            entry[1].loc[i, 'Count by Mention of Individuals'] = ', '.join(['{}: {}'.format(k, v) for k, v in total.items()])\n",
    "        else: \n",
    "            entry[1].loc[i, 'Count of Unique Indivuals'] = 'No Hits'\n",
    "            entry[1].loc[i, 'Count by Mention of Individuals'] = 'No Hits'\n",
    "    entry[1].to_csv('../../OutputPersons/PersonsBreakdown/{}.csv'.format('_'.join(entry[0].split('.')[4:6])), index=False)\n",
    "    # entry[1].to_csv(entry[0], index=False)\n",
    "    end = time.time()\n",
    "    print('Time: ', end-start, 'seconds for ', entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a0b6b-06f5-429d-ad82-6a60c8614e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a5cac-4ea8-4958-8947-478803715714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
