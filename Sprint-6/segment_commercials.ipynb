{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06e95062-9b13-403e-b3ce-758c5462c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72ef8814-90f3-41aa-9ebe-8eef7b87cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tuple(row):\n",
    "    list_of_tuples = []\n",
    "    for item in row:\n",
    "        for string in item.split():\n",
    "            if string.isnumeric():\n",
    "                # Take everything up to the number as a single string\n",
    "                list_of_tuples.append((item[:item.find(string) - 1], string)) # Create a tuple (Topic, Frequency)\n",
    "    return list_of_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9798b6b7-106c-4c42-ba17-7e928328a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(test_str):\n",
    "    ret = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in test_str:\n",
    "        if i == '(':\n",
    "            skip1c += 1\n",
    "        elif i == ')' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            ret += i\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6545c679-bebc-4e29-975f-b89d0a52c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../Data/CorporaData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd0607b-c805-44f1-bce3-e0fd566ad189",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for folder in os.listdir(path):\n",
    "    if folder != '.DS_Store' and folder != '.ipynb_checkpoints':\n",
    "        for file in os.listdir(os.path.join(path, folder)):\n",
    "            if file != '.ipynb_checkpoints':\n",
    "                files.append(('../../Data/CommercialData/{}/{}_{}.txt'.format(\n",
    "                    file.split('.')[0], file.split('.')[0], file.split('.')[2]), os.path.join(path, os.path.join(folder, file))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d194250-57fe-4e49-9f29-01018137f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpl in files:\n",
    "    df = pd.read_csv(tpl[1])\n",
    "    df.columns = ['URL', 'Title', 'Text']\n",
    "    df['Text'] = df['Text'].apply(lambda text: str(text))\n",
    "    df['Text'] = df['Text'].apply(lambda text: text.replace('[[TIME.START]] ', '('))\n",
    "    df['Text'] = df['Text'].apply(lambda text: text.replace(' [[TIME.END]]', ')'))\n",
    "    df['Text'] = df['Text'].apply(lambda text: str(text).split('TOPICS: TOPIC FREQUENCY ')[0])\n",
    "    df['Text'] = df['Text'].apply(lambda text: str(text)[str(text).find('[[TITLE.END]] ') + len('[[TITLE.END]] '):])\n",
    "    df['Text'] = df['Text'].apply(lambda text: re.sub('<[^>]+>', '', text))\n",
    "    df['Text'] = df['Text'].apply(lambda text: re.sub(r'[^\\w\\s]', '', text))\n",
    "    df['Text'] = df['Text'].apply(lambda text: ' '.join([word for word in text.split() if word not in cachedStopWords]))\n",
    "    df['Text'] = df['Text'].apply(lambda text: a(text))\n",
    "    corpora_df.to_csv('../../OutputCommercialsDataframes/{}/{}_{}_{}'.format(tpl[1].split('/')[4].split('.')[0], tpl[1].split('/')[4].split('.')[0], tpl[1].split('/')[4].split('.')[2], 'output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7594f8e1-b042-4257-bc55-f2e41ab9f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_path = '../../OutputCommercialsDataframes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "057e476b-6ee6-4672-9b93-281daba9f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for folder in os.listdir(comm_path):\n",
    "    if folder != '.DS_Store' and folder != '.ipynb_checkpoints':\n",
    "        for file in os.listdir(os.path.join(comm_path, folder)):\n",
    "            if file != '.ipynb_checkpoints':\n",
    "                files.append(('../../Data/CommercialData/{}/{}_{}.txt'.format(\n",
    "                    file.split('_')[0], file.split('_')[0], file.split('_')[1]), os.path.join(comm_path, os.path.join(folder, file))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f67b24c-3c41-428f-83c4-bb51f5ab2942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../Data/CommercialData/FOXNEWS/FOXNEWS_2016.txt',\n",
       " '../OutputCommercialsDataframes/FOXNEWS/FOXNEWS_2016_output.csv')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2e1ed5f-97ad-4db4-859e-cde413a66e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "commercials = {'Bloomberg': {}, \n",
    "              'CNBC': {},\n",
    "              'CNN': {},\n",
    "              'FBC': {},\n",
    "              'FOXNEWS': {},\n",
    "              'MSNBC': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ca8e901-841e-4a16-9c9a-f94c5b872aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tpl in files:\n",
    "    corpora_df = pd.read_csv(tpl[1])\n",
    "    \n",
    "    with open(tpl[0], 'r') as f: # Get the potential commericials\n",
    "        comm_lines = f.readlines()\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    for i in range(len(corpora_df.index)):\n",
    "        commercials[tpl[1].split('/')[2]][corpora_df.loc[i, 'Title']] = []\n",
    "        \n",
    "    for i in range(len(corpora_df.index)):\n",
    "        segmented_text = str(corpora_df.loc[i, 'RawText_preprocessed']).split('[[TIME.START]]')\n",
    "        for segment in segmented_text:\n",
    "            for comm in comm_lines:\n",
    "                if comm in segment:\n",
    "                    commercials[tpl[1].split('/')[2]][corpora_df.loc[i, 'Title']].append(segment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a438b046-4d6d-411c-826f-d43b259ae74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in commercials['FOXNEWS'].items():\n",
    "    if v:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc05975-cd44-4af8-a4be-9a9a812eac68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
