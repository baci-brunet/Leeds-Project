{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c4447e-b5f2-45b6-a985-a8f111bbfc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from os.path import exists\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac374364-e1aa-494b-9ae3-6936289ae958",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:2em;\">Read in Cleaned Firm Name Data</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1f539-be0a-419a-b7d9-c91bdca5fae0",
   "metadata": {},
   "source": [
    "**CRSP Firm Name Data (for testing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae92fefe-6adc-4356-b5c7-45e9205705aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "firms_df = pd.read_csv('../../Data/Diego/conames_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be32af80-c71d-412c-9459-d2c0651e7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_firms = []\n",
    "for i in range(len(firms_df.index)):\n",
    "    if firms_df.loc[i, 'done'] == 1:\n",
    "        if isinstance(firms_df.loc[i, 'regexes'], str):\n",
    "            all_firms.append(firms_df.loc[i, 'regexes'])\n",
    "        else:\n",
    "            all_firms.append(firms_df.loc[i, 'names.firms.1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab5e4b-dd12-424d-8437-bced78cdc13f",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:2em;\">Helper Functions</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54ae43-d82d-4246-bd21-47ec5d9a440c",
   "metadata": {},
   "source": [
    "**Function to Generate Tuples From Topic Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a84c16-81a7-40a8-929d-7251334b5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tuple(row):\n",
    "    list_of_tuples = []\n",
    "    for item in row:\n",
    "        for string in item.split():\n",
    "            if string.isnumeric():\n",
    "                # Take everything up to the number as a single string\n",
    "                list_of_tuples.append((item[:item.find(string) - 1], string)) # Create a tuple (Topic, Frequency)\n",
    "    return list_of_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c461b5-1d36-4b3b-b07f-0a0322b96f31",
   "metadata": {},
   "source": [
    "**Row-Wise Function that matches Firm Names in Raw Data (1 to 1)**\n",
    "\n",
    "Changed this because I removed some text preprocessing from RawText (changes: [[TIME.START]] and [[TIME.END]] from TIME START and TIME END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b70644-f548-4a2b-bbfc-5a393a654936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_hits(row, firm_list):\n",
    "#     loi = []\n",
    "#     for segment in str(row).split('[[TIME.START]]'):\n",
    "#         for firm in firm_list:\n",
    "#             if ' {} '.format(firm.strip()) in segment:\n",
    "#                 loi.append((firm.split('(')[0].strip(), segment.split('[[TIME.END]]')[0].strip(), segment.lower().count(' {} '.format(firm.strip()))))\n",
    "#     if not loi:\n",
    "#         return 'No Hits'\n",
    "#     else:\n",
    "#         return ', '.join(['{}/{}/{}'.format(tpl[0], tpl[1], tpl[2]) for tpl in loi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc44a10-7c47-44a4-b931-522fa29d957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hits(row, firm_list):\n",
    "    loi = []\n",
    "    for segment in str(row).split('[[TIME.START]]'):\n",
    "        for firm in firm_list:\n",
    "            if '*' in firm:\n",
    "                search_term = r'\\b{}'.format(firm.strip('*'))\n",
    "            else:\n",
    "                search_term = r'\\b{}\\b'.format(firm)\n",
    "            if re.search(search_term.lower(), segment.lower()):\n",
    "                loi.append((firm, segment.split('[[TIME.END]]')[0].strip(), len(re.findall(search_term.lower(), segment.lower()))))\n",
    "    if not loi:\n",
    "        return 'No Hits'\n",
    "    else:\n",
    "        return ', '.join(['{}/{}/{}'.format(tpl[0], tpl[1], tpl[2]) for tpl in loi])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc259b0-967b-4b9b-a280-641943de0e0c",
   "metadata": {},
   "source": [
    "**Row-Wise Function that adds the Un-processed Firm Name to the Hits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b58a0e-697e-425c-af37-cfb9914c6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ogs(row, firms, firms_og):\n",
    "    org_hits = []\n",
    "    for org in str(row).split(','):\n",
    "        if org == 'No Hits':\n",
    "            return 'No Hits'\n",
    "        else:\n",
    "            org_hits.append('{} ({})'.format(org, firms_og[firms.index(org.lstrip())]))\n",
    "    return ', '.join(org_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f8672-2634-436f-b914-bbc7bd77dfd7",
   "metadata": {},
   "source": [
    "**<span style=\"font-size:2em;\">Create tuples of Corpora Files and Spacy Files</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0433c4-0d79-4285-bbfc-48cba07e2e1d",
   "metadata": {},
   "source": [
    "**Define Path to Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4e76a9-2ec9-41ac-881e-67fe6437aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_data = '../../Data/CorporaData'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b9fa1-0338-46fc-bec5-9d65799af465",
   "metadata": {},
   "source": [
    "**Iterate through Directories and Match Corresponding Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472df4fe-a0b1-4842-a587-947e4e2d9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for folder in os.listdir(corpora_data):\n",
    "    if folder != '.DS_Store':\n",
    "        for corpora_file in os.listdir(os.path.join(corpora_data, folder)):\n",
    "            if corpora_file != '.DS_Store' and corpora_file != '.ipynb_checkpoints':\n",
    "                files.append((os.path.join(corpora_data, os.path.join(folder, corpora_file))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bb5570-e6e0-4803-99d4-ed56c830e8c1",
   "metadata": {},
   "source": [
    "**Process Raw Text for Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a51d59-b9df-436a-877d-130d56550c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../Data/CorporaData/2021/FOXNEWS.Text.2021.1.csv done in 2.6922757625579834 seconds\n",
      "File ../Data/CorporaData/2021/MSNBC.Text.2021.1.csv done in 3.061405897140503 seconds\n",
      "File ../Data/CorporaData/2021/CNBC.Text.2021.1.csv done in 0.961961030960083 seconds\n",
      "File ../Data/CorporaData/2021/FBC.Text.2021.1.csv done in 1.0513768196105957 seconds\n",
      "File ../Data/CorporaData/2021/CNN.Text.2021.1.csv done in 2.3217687606811523 seconds\n",
      "File ../Data/CorporaData/2021/Bloomberg.Text.2021.1.csv done in 0.8401088714599609 seconds\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    # if exists('../OutputRaw/{}/{}_{}_output.csv'.format(file.split('/')[4].split('.')[0], file.split('/')[4].split('.')[0], file.split('/')[4].split('.')[2])):\n",
    "    #     continue\n",
    "    # else:\n",
    "    start = time.time()\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = ['URL', 'Title', 'RawText']\n",
    "    df['Topics'] = df['RawText'].apply(\n",
    "        lambda text: str(text)[str(text).find('TOPICS: TOPIC FREQUENCY ') + len('TOPICS: TOPIC FREQUENCY '):].split('; '))\n",
    "    df['Topics'] = df['Topics'].apply(lambda text: generate_tuple(text))\n",
    "    df['RawText_preprocessed'] = df['RawText'].apply(lambda text: str(text).split('TOPICS: TOPIC FREQUENCY ')[0])\n",
    "    df['RawText_preprocessed'] = df['RawText_preprocessed'].apply(lambda text: str(text)[str(text).find('[[TITLE.END]] ') + len('[[TITLE.END]] '):])       \n",
    "    del df['RawText']\n",
    "    df.to_csv('../../OutputRaw/{}/{}_{}_output.csv'.format(\n",
    "        file.split('/')[4].split('.')[0], file.split('/')[4].split('.')[0], file.split('/')[4].split('.')[2]), index=False)\n",
    "    end = time.time()\n",
    "    print('File {} done in {} seconds'.format(file, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde98e6f-16c8-4c32-b159-d8cbf1a659e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../../OutputRaw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede33753-83e1-4b50-9927-bef5df8fd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = []\n",
    "for folder in os.listdir(output_path):  \n",
    "    if folder != '.DS_Store' and folder != '.ipynb_checkpoints':\n",
    "        for file in os.listdir(os.path.join(output_path, folder)):\n",
    "            if file != '.ipynb_checkpoints':\n",
    "                output_files.append(os.path.join(output_path, os.path.join(folder, file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7abbc7c-5064-456f-b810-5d673174ebf3",
   "metadata": {},
   "source": [
    "**Match Data and Record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0265422c-989a-4d6b-8968-dcda65385f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output_file in output_files:\n",
    "    start = time.time()\n",
    "    dataframe = pd.read_csv(output_file)\n",
    "    if 'Matched Organizations' in dataframe.columns:\n",
    "        print(output_file)\n",
    "        continue\n",
    "    else:\n",
    "        final_df = pd.DataFrame(columns=['URL', 'Show Title', 'Topics', 'Matched Organizations'])\n",
    "        final_df['URL'] = dataframe['URL']\n",
    "        final_df['Show Title'] = dataframe['Title']\n",
    "        final_df['Topics'] = dataframe['Topics']\n",
    "        print('Matching...')\n",
    "        final_df['Matched Organizations'] = dataframe['RawText_preprocessed'].apply(lambda text: add_hits(text, all_firms))\n",
    "        print('Done.')\n",
    "        end = time.time()\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        print('File {} done in {} seconds'.format(output_file, end-start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
